# ðŸ“– GuÃ­a Manual: CreaciÃ³n de Paneles en Grafana

## Panel 1: ðŸš¨ Estado de AnomalÃ­a (Stat)

**Tipo:** Stat Panel  
**Data Source:** Prometheus

### Query:

```promql
log_anomalia_detectada
```

### ConfiguraciÃ³n:

- **Visualization:** Stat
- **Color Mode:** Background
- **Graph Mode:** Area
- **Thresholds:**
    - Base: Green (0)
    - Anomaly: Red (1)

---

## Panel 2: ðŸ“Š Score de AnomalÃ­a Actual (Stat)

**Tipo:** Stat Panel  
**Data Source:** Prometheus

### Query:

```promql
log_anomalia_score
```

### ConfiguraciÃ³n:

- **Visualization:** Stat
- **Decimals:** 4
- **Thresholds:**
    - Green: 0
    - Yellow: 0.1
    - Red: 0.15 (tu umbral)

---

## Panel 3: ðŸ“ Total de Logs Procesados (Stat)

**Tipo:** Stat Panel  
**Data Source:** Prometheus

### Query:

```promql
logs_procesados_total
```

### ConfiguraciÃ³n:

- **Visualization:** Stat
- **Color Mode:** Value
- **Graph Mode:** Area

---

## Panel 4: ðŸ“ˆ EvoluciÃ³n del Score de AnomalÃ­a (Time Series)

**Tipo:** Time series  
**Data Source:** Prometheus

### Query:

```promql
log_anomalia_score
```

### ConfiguraciÃ³n:

- **Line Interpolation:** Smooth
- **Line Width:** 2
- **Fill Opacity:** 20
- **Show Points:** Auto
- **Threshold:** Line at 0.15 (red)
- **Legend:** Show min, max, mean

---

## Panel 5: ðŸ”´ DetecciÃ³n de AnomalÃ­as en Tiempo Real (Time Series)

**Tipo:** Time series  
**Data Source:** Prometheus

### Query:

```promql
log_anomalia_detectada
```

### ConfiguraciÃ³n:

- **Line Interpolation:** Step After
- **Fill Opacity:** 50
- **Value Mappings:**
    - 0 â†’ "Normal" (Green)
    - 1 â†’ "AnomalÃ­a" (Red)

---

## Panel 6: âš¡ Tasa de Procesamiento (Time Series)

**Tipo:** Time series  
**Data Source:** Prometheus

### Query:

```promql
rate(logs_procesados_total[1m])
```

### ConfiguraciÃ³n:

- **Draw Style:** Bars
- **Fill Opacity:** 100
- **Legend:** Show sum

---

## Panel 7: ðŸ“Š Score de AnomalÃ­a desde InfluxDB (Time Series)

**Tipo:** Time series  
**Data Source:** InfluxDB

### Flux Query:

```flux
from(bucket: "network_traffic")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r["_measurement"] == "web_traffic")
  |> filter(fn: (r) => r["_field"] == "score_anomalia")
  |> aggregateWindow(every: v.windowPeriod, fn: mean, createEmpty: false)
  |> yield(name: "mean")
```

### ConfiguraciÃ³n:

- **Line Interpolation:** Smooth
- **Fill Opacity:** 10
- **Legend:** Show mean, max

---

## Panel 8: ðŸ“‹ Tabla de Logs Recientes (Table)

**Tipo:** Table  
**Data Source:** InfluxDB

### Flux Query:

```flux
from(bucket: "network_traffic")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r["_measurement"] == "web_traffic")
  |> filter(fn: (r) => r["_field"] == "score_anomalia" or 
                       r["_field"] == "is_anomaly" or 
                       r["_field"] == "response_size")
  |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
  |> keep(columns: ["_time", "ip", "method", "status", "url", 
                    "score_anomalia", "is_anomaly", "response_size"])
  |> sort(columns: ["_time"], desc: true)
  |> limit(n: 100)
```

### Configuraciones Especiales:

**Columna is_anomaly:**

- Cell Options: Color Background
- Value Mappings:
    - 0 â†’ "âœ“ Normal" (Green)
    - 1 â†’ "âš  AnomalÃ­a" (Red)

**Columna score_anomalia:**

- Cell Options: Color Background
- Thresholds:
    - Green: < 0.1
    - Yellow: 0.1 - 0.15
    - Red: > 0.15

---

## Panel 9: ðŸŒ Top 10 IPs con AnomalÃ­as (Pie Chart)

**Tipo:** Pie chart  
**Data Source:** InfluxDB

### Flux Query:

```flux
from(bucket: "network_traffic")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r["_measurement"] == "web_traffic")
  |> filter(fn: (r) => r["_field"] == "is_anomaly")
  |> group(columns: ["ip"])
  |> sum()
  |> group()
  |> sort(columns: ["_value"], desc: true)
  |> limit(n: 10)
```

### ConfiguraciÃ³n:

- **Legend:** Table with values
- **Pie Type:** Pie (or Donut)

---

## Panel 10: ðŸ”§ AnomalÃ­as por MÃ©todo HTTP (Time Series)

**Tipo:** Time series  
**Data Source:** InfluxDB

### Flux Query:

```flux
from(bucket: "network_traffic")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r["_measurement"] == "web_traffic")
  |> filter(fn: (r) => r["_field"] == "is_anomaly")
  |> group(columns: ["method"])
  |> aggregateWindow(every: v.windowPeriod, fn: sum, createEmpty: false)
  |> yield(name: "sum")
```

### ConfiguraciÃ³n:

- **Draw Style:** Bars
- **Stacking:** Normal
- **Legend:** Show sum by method

---

# ðŸŽ¨ Tips de PersonalizaciÃ³n

## Colores Consistentes

```
Verde:  #73BF69 (Normal)
Amarillo: #FADE2A (Warning)
Rojo:   #F2495C (AnomalÃ­a)
Azul:   #5794F2 (Info)
```

## Refresh Rate

- Dashboard Settings â†’ Time Options â†’ Refresh: **5s**
- Range: **Last 1 hour** (ajustar segÃºn necesidad)

## OrganizaciÃ³n

- Row 1: MÃ©tricas instantÃ¡neas (Stats)
- Row 2-3: GrÃ¡ficas temporales
- Row 4: Tablas detalladas
- Row 5: AnÃ¡lisis agregados

# ðŸ”” ConfiguraciÃ³n de Alertas en Grafana

## Alerta 1: DetecciÃ³n de AnomalÃ­a

### Paso 1: Crear Alert Rule

1. Ve al panel "ðŸš¨ Estado de AnomalÃ­a"
2. Click en el tÃ­tulo del panel â†’ **Edit**
3. Tab **Alert** â†’ **Create alert rule from this panel**

### ConfiguraciÃ³n:

```yaml
Rule name: AnomalÃ­a Detectada en Logs
Evaluate every: 10s
For: 30s  # Esperar 30s antes de alertar

# CondiciÃ³n
WHEN: log_anomalia_detectada
IS ABOVE: 0.5  # Detecta cuando pasa de 0 a 1

# Labels
severity: critical
team: security
```

### Mensaje de Alerta:

```
ðŸš¨ ANOMALÃA DETECTADA
Score: {{ $values.log_anomalia_score }}
Revisa el dashboard inmediatamente
```

---

## Alerta 2: Score de AnomalÃ­a Alto

### ConfiguraciÃ³n:

```yaml
Rule name: Score de AnomalÃ­a Elevado
Evaluate every: 30s
For: 1m

# CondiciÃ³n
WHEN: log_anomalia_score
IS ABOVE: 0.12  # Umbral preventivo (antes del 0.15)

# Labels
severity: warning
team: operations
```

### Mensaje:

```
âš ï¸ Score de AnomalÃ­a Elevado
Valor actual: {{ $values.log_anomalia_score }}
Umbral crÃ­tico: 0.15
```

---

## Alerta 3: Procesamiento Detenido

### ConfiguraciÃ³n:

```yaml
Rule name: Sistema de DetecciÃ³n Detenido
Evaluate every: 1m
For: 2m

# CondiciÃ³n
WHEN: increase(logs_procesados_total[2m])
IS BELOW: 1  # No ha procesado logs en 2 minutos

# Labels
severity: critical
team: infrastructure
```

---

## Canales de NotificaciÃ³n

### Email

1. **Alerting** â†’ **Contact points** â†’ **New contact point**
2. **Name:** Email Team
3. **Integration:** Email
4. **Addresses:** tu-email@example.com

### Slack (Opcional)

```yaml
Name: Slack Security
Integration: Slack
Webhook URL: https://hooks.slack.com/services/YOUR/WEBHOOK/URL
Username: Grafana Alerts
```

### Discord (Opcional)

```yaml
Name: Discord Alerts
Integration: Discord
Webhook URL: https://discord.com/api/webhooks/YOUR_WEBHOOK
```

---

## Notification Policy

1. **Alerting** â†’ **Notification policies**
2. **Default policy:**
    - **Contact point:** Email Team
    - **Group by:** alertname, severity
    - **Group wait:** 30s
    - **Group interval:** 5m
    - **Repeat interval:** 4h

---

## Test de Alertas

### Generar AnomalÃ­a Manual:

```bash
# Generar trÃ¡fico anÃ³malo (mÃºltiples requests rÃ¡pidos)
for i in {1..100}; do
  curl -X POST http://localhost/anomalous-endpoint-$i
done
```

### Verificar:

1. Dashboard debe mostrar score > 0.15
2. Panel "Estado de AnomalÃ­a" debe ponerse ROJO
3. Alerta debe dispararse en 30s
4. Email/Slack debe recibirse